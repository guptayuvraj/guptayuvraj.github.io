<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title> on Blog </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://guptayuvraj.github.io/tags/virtualization/index.xml</link>
    <language>en-us</language>
    
    
    <updated>Mon, 01 Jan 0001 00:00:00 UTC</updated>
    
    <item>
      <title>NexentaStor</title>
      <link>http://guptayuvraj.github.io/post/NexentaStor/</link>
      <pubDate>Wed, 13 Apr 2016 00:00:00 UTC</pubDate>
      
      <guid>http://guptayuvraj.github.io/post/NexentaStor/</guid>
      <description>&lt;p&gt;Nexenta – NexentaStor:  delivers high-performance, ultra-scalable, cloud- and virtualization-optimized storage solutions. Nexenta supplies the software. You leverage your hardware. Does not provide object storage.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Delivers built-proof data integrity and unlimited scalability for Big Data- and Cloud-optimized storage solutions. Nexenta’s OpenStorage platform allows for a broader range of virtualization and cloud-computing services at a much lower cost.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;High-Availability Clustering.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Unlimited Snapshots &amp;amp; Clones:&lt;/strong&gt; NexentaStor uses copy on write (COW), this means live data is never overwritten; instead, it writes data to a new block before changing the data pointers and committing the write.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Inherent Virtualization&lt;/strong&gt; – NexentaStor supports all the mainstream virtualization vendors; Microsoft Hyper-V, Citrix Xen and VMware vSphere.
Uses ZFS.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Recommended system Requirement for NexentaStor Community Edition:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;64 bit processor (32 bit not recommended for production).&lt;/p&gt;

&lt;p&gt;2 GB RAM minimum for evaluation (recommend 4 to 8 GB), Production use 8 GB minimum plus 1 GB per 1 TB raw disk space minimum (depending on use-case more may be highly desirable), or 2 GB per 1 TB raw for high-end performance deployments. If planning to use deduplication, please contact for sizing assistance.&lt;/p&gt;

&lt;p&gt;2 identical relatively small disks for high-availability system folder.&lt;/p&gt;

&lt;p&gt;Additional drives/storage for data volumes&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What is Desktop Virtualization</title>
      <link>http://guptayuvraj.github.io/post/What-is-Desktop-Virtualization/</link>
      <pubDate>Sun, 10 Apr 2016 00:00:00 UTC</pubDate>
      
      <guid>http://guptayuvraj.github.io/post/What-is-Desktop-Virtualization/</guid>
      <description>&lt;p&gt;Desktop Virtualization is the concept of isolating an operating system (OS) from the client that is used to access it. It is also known as client virtualization which separates a computer desktop environment from the physical computer. It is used as a new approach to the provisioning, delivery, and management of user desktops in the enterprise. The main principle behind this new approach is leveraging existing and well-proven virtualization technologies to virtualize not only servers but also user desktops (the workstations). The resulting “virtualized” desktop is stored on a remote central server, instead of on the local storage of remote client; thus, when users work from their remote desktop client, all of the programs, applications, processes and data used are kept and run centrally, allowing users to access their desktops on any capable device, such as a traditional personal computer, notebook computer, smart phone, or thin client. Users may be geographically scattered, but all must be connected to the central machine by a local area network, a wide area network, or the public Internet.&lt;/p&gt;

&lt;p&gt;Desktop Virtualization replaces the traditional model where users run all the applications and store data on their desktop services. Instead the whole environment of the desktop experience would be executed in the data center servers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../images/Desktop-Virtualization.jpg&#34; alt=&#34;&#34; title=&#34;Desktop-Virtualization.jpg&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Best Practices while going for Storage Virtualization</title>
      <link>http://guptayuvraj.github.io/post/Best-Practices-Storage-Virtualization/</link>
      <pubDate>Sat, 09 Apr 2016 00:00:00 UTC</pubDate>
      
      <guid>http://guptayuvraj.github.io/post/Best-Practices-Storage-Virtualization/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Set your scope and objectives.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Begin the vendor selection process with specific goals and objectives. We must fully understand what we want to achieve or overcome with storage virtualization.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Arrange Proper Staff Training&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Address skill gaps so we can properly asses different virtualization approaches. Storage virtualization requires specific training and knowledge, so it’s necessary to asses current IT staff for skills and identify potential knowledge gaps. Also consider vendor specific training once finalized.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Leverage Storage Resource Management (SRM)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Properly instrumenting SRM tools providing full discovery and visibility of virtual, logic and physical storage.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Establish Storage Management Standards&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reduce costs associated with managing multiple site management. When you establish storage management standards including standard LUN sizes and naming conventions—you can more easily interchange similar storage subsystems, reducing complicated planning exercises. Standard configurations simplify both production environment planning and disaster recovery site recovery planning.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Implement Service Maintenance Best Practices&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Accurately calculate capital and operational expenses for applications.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Implement Storage Virtualization</title>
      <link>http://guptayuvraj.github.io/post/Implement-Storage-Virtualization/</link>
      <pubDate>Fri, 08 Apr 2016 00:00:00 UTC</pubDate>
      
      <guid>http://guptayuvraj.github.io/post/Implement-Storage-Virtualization/</guid>
      <description>&lt;p&gt;Why do we need to implement Storage Virtualization?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Increasing Storage Demands&lt;/li&gt;
&lt;li&gt;Too long to do backup and restore.&lt;/li&gt;
&lt;li&gt;Limited Space in Data Center.&lt;/li&gt;
&lt;li&gt;Need to improve DR capabilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Approach for implementation of Storage Virtualization?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Host Based:&lt;/strong&gt;  Physical drives are handled by traditional device driver, while a software layer above device driver intercepts I/O requests, looks up metadata and redirects I/O.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Simple to design and code.&lt;/li&gt;
&lt;li&gt;Supports any storage type.&lt;/li&gt;
&lt;li&gt;Improves storage utilization without thin provisioning restrictions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Replication and data migration only possible locally to that host.&lt;/li&gt;
&lt;li&gt;Traditional data recovery following a server disk crash is impossible.&lt;/li&gt;
&lt;li&gt;Storage utilization optimized only on per host basis.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Network Based:&lt;/strong&gt;  Storage virtualization is viewed as a network-based device using fibre channel networks connected as SAN. A fibre channel switch which is in between the host and storage will virtualize all requests. Interestingly operating system on the host doesn’t know it’s happening as it this method doesn’t rely on operating system.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Simple Management Interface.&lt;/li&gt;
&lt;li&gt;Replication services across heterogeneous devices.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Difficult to implement fast metadata updates in switches.&lt;/li&gt;
&lt;li&gt;Out-of-band requires specific host based software.&lt;/li&gt;
&lt;li&gt;In-band adds latency to I/O.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Implementation of Network based&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Appliance Based:&lt;/strong&gt; an appliance residing between client and storage array implements storage virtualization layer and becomes new storage target. When the data is sent to appliance via client storage virtualization features can be enabled such as snapshot, thin provisioning and data replication.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Versatility&lt;/li&gt;
&lt;li&gt;Cost&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Switch Based:&lt;/strong&gt; an application that resides in server connected to fibre channel SAN switch. Though it sits in between host and storage but it may use different techniques for metadata mapping.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Faster Speed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Expensive.&lt;/li&gt;
&lt;li&gt;Lacks features such as thin provisioning.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Storage Device Based:&lt;/strong&gt; the primary storage controller allows direct attachment of other storage controllers and provides virtualization services. It will provide pooling and metadata management services.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;No additional hardware or infrastructure requirement.&lt;/li&gt;
&lt;li&gt;Provides most of the benefits of storage virtualization.&lt;/li&gt;
&lt;li&gt;Does not add latency to individual I/O.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Storage utilization optimized only across the connected controllers&lt;/li&gt;
&lt;li&gt;Replication and data migration only possible across the connected controllers and same vendors device for long distance support&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Array Based:&lt;/strong&gt; storage virtualization layer lives entirely within storage array.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Challenges  of Storage Virtualization</title>
      <link>http://guptayuvraj.github.io/post/Challenges-Storage-Virtualization/</link>
      <pubDate>Thu, 07 Apr 2016 00:00:00 UTC</pubDate>
      
      <guid>http://guptayuvraj.github.io/post/Challenges-Storage-Virtualization/</guid>
      <description>&lt;ol&gt;
&lt;li&gt;Storage Architecture becomes  much more complicated.&lt;/li&gt;
&lt;li&gt;More complication may lead to troubleshooting problems.&lt;/li&gt;
&lt;li&gt;Problem determination and fault isolation can become complex.&lt;/li&gt;
&lt;li&gt;Arise of situations in which physical storage resources are overcommitted.&lt;/li&gt;
&lt;li&gt;Backing out of failed implementation.&lt;/li&gt;
&lt;li&gt;Interoperability.&lt;/li&gt;
&lt;li&gt;Management of Meta Data.&lt;/li&gt;
&lt;li&gt;Higher Latency&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Benefits of Storage Virtualization</title>
      <link>http://guptayuvraj.github.io/post/Benefits-Storage-Virtualization/</link>
      <pubDate>Wed, 06 Apr 2016 00:00:00 UTC</pubDate>
      
      <guid>http://guptayuvraj.github.io/post/Benefits-Storage-Virtualization/</guid>
      <description>&lt;ol&gt;
&lt;li&gt;Improved Storage Management in an IT environment&lt;/li&gt;
&lt;li&gt;Better availability and estimation of downtime required with automated management.&lt;/li&gt;
&lt;li&gt;Ability to migrate data while retaining  I/O access (Non disruptive data migration).&lt;/li&gt;
&lt;li&gt;Reduce the number of SAN devices.&lt;/li&gt;
&lt;li&gt;Decrease in Power consumed.&lt;/li&gt;
&lt;li&gt;Time Saving.&lt;/li&gt;
&lt;li&gt;Ease in Data Replication.&lt;/li&gt;
&lt;li&gt;Easy backup, archiving and recovery tasks.&lt;/li&gt;
&lt;li&gt;Expansion of Storage Capacity.&lt;/li&gt;
&lt;li&gt;Easy Updates&lt;/li&gt;
&lt;li&gt;Ability to increase Storage Volume Size in real time.&lt;/li&gt;
&lt;li&gt;Increased loading and backup speed.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>What is Storage Virtualization</title>
      <link>http://guptayuvraj.github.io/post/What-is-Storage-Virtualization/</link>
      <pubDate>Tue, 05 Apr 2016 00:00:00 UTC</pubDate>
      
      <guid>http://guptayuvraj.github.io/post/What-is-Storage-Virtualization/</guid>
      <description>&lt;p&gt;It is the abstraction of physical media (hard disks or solid state drives etc) from the attaching servers which treats the storage as a single logical entity without regard to the hierarchy of physical media that is involved. Storage virtualization means adding an abstraction layer of software that hides the physical devices from the user and allows all devices to be managed as a single pool.
It adds a new layer of software or hardware in between the storage systems and servers so that the applications would not require to know to which logical drive, partitions or storage subsystems the data resides in.&lt;/p&gt;

&lt;p&gt;Within the context of a storage system, there are two primary types of virtualization that can occur:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Block virtualization&lt;/strong&gt; used in this context refers to the abstraction (separation) of logical storage (partition) from physical storage so that it may be accessed without regard to physical storage or heterogeneous structure. This separation allows the administrators of the storage system greater flexibility in how they manage storage for end users. The act of applying virtualization , to one or more block based (storage) services for the purpose of providing a new aggregated, higher level, richer, simpler, secure, etc., block service to clients. Block virtualization functions can be nested. A disk drive, RAID system or volume manager all perform some form of block address to (different) block address mapping or aggregation&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;File virtualization&lt;/strong&gt; addresses the NAS challenges by eliminating the dependencies between the data accessed at the file level and the location where the files are physically stored. This provides opportunities to optimize storage use and server consolidation and to perform non-disruptive file migrations. File virtualization is the creation of an abstraction layer between file servers and the clients that access those file servers. Once deployed, the file virtualization layer manages files and file systems across servers, allowing administrators to present clients with one logical file mount for all servers&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Virtualization &amp; Private Cloud</title>
      <link>http://guptayuvraj.github.io/post/Virtualization-Private-Cloud/</link>
      <pubDate>Sun, 20 Mar 2016 00:00:00 UTC</pubDate>
      
      <guid>http://guptayuvraj.github.io/post/Virtualization-Private-Cloud/</guid>
      <description>&lt;p&gt;Virtualization of computers or operating systems hides the physical characteristics of a computing platform from users; instead it shows another abstract computing platform. A hypervisor is a piece of virtualization software that allows multiple operating systems to run on a host computer concurrently. Virtualization providers include VMware, Microsoft, and Citrix Systems. Virtualization is an enabler of cloud computing.&lt;/p&gt;

&lt;p&gt;Recently some vendors have described solutions that emulate cloud computing on private networks, referring to these as “private” or “internal” clouds (where “public” or “external” cloud describes cloud computing in the traditional mainstream sense). Private cloud products claim to deliver some of the benefits of cloud computing without the pitfalls. Hybrid solutions are also possible: building internal clouds and connecting customer data centers to those of external cloud providers. It has been reported that Eli Lilly wants to benefit from both internal and external clouds3 and that Amylin6 is looking at private cloud VMware as a complement to EC2. Other experts, however, are skeptical: one has even gone as far as to describe private clouds as absolute rubbish.7&lt;/p&gt;

&lt;p&gt;Platform Computing has recently launched a cloud management system, Platform ISF, enabling customers to manage workload across both virtual and physical environments and support multiple hypervisors and operating systems from a single interface. VMware, the market leader in virtualization technology, is moving into cloud technologies in a big way, with vSphere 4. The company is building a huge partner network of service providers and is also releasing a “vCloud API”. VMware wants customers to build a series of “virtual data centers”, each tailored to meet different requirements, and then have the ability to move workloads in the virtual data centers to the infrastructure provided by cloud vendors.&lt;/p&gt;

&lt;p&gt;Cisco, EMC and VMware have formed a new venture called Acadia. Its strategy for private cloud computing is based on Cisco’s servers and networking, VMware’s server virtualization and EMC’s storage. (Note, by the way, that EMC owns nearly 85% of VMware.) Other vendors, such as Google, disagree with VMware’s emphasis on private clouds; in return VMware says Google’s online applications are not ready for the enterprise.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
